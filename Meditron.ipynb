{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163676c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_token = \"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\"\n",
    "\n",
    "from pymed import PubMed\n",
    "from typing import List\n",
    "from haystack import component\n",
    "from haystack import Document\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# page_by_img =\"\"\"\n",
    "# <style>\n",
    "# #Mainmenu {visibility : hidden;}\n",
    "# footer {visibility : hidden;}\n",
    "# header {visibility :hidden;}\n",
    "# }\n",
    "# </style>\n",
    "# \"\"\"\n",
    "# st.markdown(page_by_img,unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"MEDITRON....!!!\")\n",
    "\n",
    "\n",
    "pubmed = PubMed(tool=\"Haystack2.0Prototype\", email=\"tilde.thurium@deepset.ai\")\n",
    "def documentize(article):\n",
    "  return Document(content=article.abstract, meta={'title': article.title, 'keywords': article.keywords})\n",
    "\n",
    "@component\n",
    "class PubMedFetcher():\n",
    "\n",
    "  @component.output_types(articles=List[Document])\n",
    "  def run(self, queries: list[str]):\n",
    "    cleaned_queries = queries[0].strip().split('\\n')\n",
    "\n",
    "    articles = []\n",
    "    try:\n",
    "      for query in cleaned_queries:\n",
    "        response = pubmed.query(query, max_results = 1)\n",
    "        documents = [documentize(article) for article in response]\n",
    "        articles.extend(documents)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Couldn't fetch articles for queries: {queries}\" )\n",
    "        return {'articles' : \"not_found\"}\n",
    "    results = {'articles': articles}\n",
    "    return results\n",
    "\n",
    "from haystack.components.generators import HuggingFaceTGIGenerator\n",
    "\n",
    "keyword_llm = HuggingFaceTGIGenerator(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=huggingface_token)\n",
    "keyword_llm.warm_up()\n",
    "\n",
    "llm = HuggingFaceTGIGenerator(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=huggingface_token)\n",
    "llm.warm_up()\n",
    "from haystack import Pipeline\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "\n",
    "keyword_prompt_template = \"\"\"\n",
    "Your task is to convert the following question into 3 keywords that can be used to find relevant medical research papers on PubMed.\n",
    "Here is an examples:\n",
    "question: \"What are the latest treatments for major depressive disorder?\"\n",
    "keywords:\n",
    "Antidepressive Agents\n",
    "Depressive Disorder, Major\n",
    "Treatment-Resistant depression\n",
    "---\n",
    "question: {{ question }}\n",
    "keywords:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer the question truthfully based on the given documents.\n",
    "If the documents don't contain an answer, use your existing knowledge base.\n",
    "\n",
    "q: {{ question }}\n",
    "Articles:\n",
    "{% for article in articles %}\n",
    "  {{article.content}}\n",
    "  keywords: {{article.meta['keywords']}}\n",
    "  title: {{article.meta['title']}}\n",
    "{% endfor %}\n",
    "\n",
    "\"\"\"\n",
    "keyword_prompt_builder = PromptBuilder(template=keyword_prompt_template)\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "fetcher = PubMedFetcher()\n",
    "\n",
    "pipe = Pipeline()\n",
    "\n",
    "pipe.add_component(\"keyword_prompt_builder\", keyword_prompt_builder)\n",
    "pipe.add_component(\"keyword_llm\", keyword_llm)\n",
    "pipe.add_component(\"pubmed_fetcher\", fetcher)\n",
    "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipe.add_component(\"llm\", llm)\n",
    "\n",
    "pipe.connect(\"keyword_prompt_builder.prompt\", \"keyword_llm.prompt\")\n",
    "pipe.connect(\"keyword_llm.replies\", \"pubmed_fetcher.queries\")\n",
    "\n",
    "pipe.connect(\"pubmed_fetcher.articles\", \"prompt_builder.articles\")\n",
    "pipe.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n",
    "\n",
    "def ask(question):\n",
    "  output = pipe.run(data={\"keyword_prompt_builder\": {\"question\": question},\n",
    "                          \"prompt_builder\": {\"question\": question},\n",
    "                          \"llm\": {\"generation_kwargs\": {\"max_new_tokens\": 500}}})\n",
    "  # print(question)\n",
    "  # print(output['llm']['replies'][0])\n",
    "  st.success(\"Generated successfully\")\n",
    "  st.write(output['llm']['replies'][0])\n",
    "\n",
    "def body():\n",
    "  text = st.text_input(\"Please enter some text to generate image\")\n",
    "  if (st.checkbox(\"SUBMIT\")):\n",
    "    answer = ask(text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    body()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
